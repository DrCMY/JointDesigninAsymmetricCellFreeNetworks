%
\documentclass[journal]{IEEEtran}
\input{Packages.tex}
\import*{Files/}{NewCommands.tex}
\hyphenation{op-tical net-works semi-conduc-tor}
\usepackage{amsbsy}
\usepackage{amstext}

\begin{document}

\title{Joint User / Access Point Selection and Combining in Cell-Free Networks}
%\author{Cenk M. Yetis,~\IEEEmembership{Member,~IEEE}, Emil Bj\"{o}rnson,~\IEEEmembership{Senior Member,~IEEE}, and Pontus Giselsson
%\thanks{C. M. Yetis and P. Giselsson are with the Department of Automatic Control, Lund University, 22100, Lund, Sweden (cenkmyetis@ieee.org; \mbox{pontus.giselsson@control.lth.se}). %E. Bj\"{o}rnson is with the Department of Electrical Engineering (ISY), Link\"{o}ping University, 58183, Link\"{o}ping, Sweden (emil.bjornson@liu.se).}}
%\textit{ (Corresponding author: C. M. Yetis.)} 
\maketitle

%\tableofcontents
\section*{Abstract} %\label{sec:Abstract}
In this paper, the uplink communications in $\mbcf$ networks is considered. Access points are connected to a network controller via backhaul links. At the network controller, users' signals are decoded through the combiners that are designed by a sparsity solver known as sparse group lasso. Sparse group lasso does selection both at the group (i.e., user) and within the group (i.e., access point) levels. Numerical results indicate that the proposed solution achieves the best $\mbsr$ performance as the network and selection sizes are increased.

\section{Introduction} \label{sec:Introduction}
\textit{Notations}: Throughout the paper, $(.)^T$, $(.)^H$, $(.)^{-1}$, and $\ttr\{.\}$ denote the transpose, conjugate transpose, inverse, and trace operations of a matrix, respectively. $\|.\|_p$ and $\|.\|_F$ denote the $\ell_p$ vector and Frobenius matrix norms, respectively. $a\siij$ is the entry in the $i\ssth$ row and the $j\ssth$ column of the matrix $\mbfA$. ${\mathcal{CN}(0,x)}$ denotes the complex Gaussian distribution with zero mean and variance $x$. $E\{.\}$ and $|.|$ are the expectation and absolute value operators, respectively.
\section{System Model} \label{sec:SystemModel}
We consider $L$ $\mbsa$ access points (APs) and $K$ $\mbsa$ users. The received signal at AP $l$ is given as
\begin{equation}\label{eq:ReceivedSignalatAP}
y_l=\sqrt{p}\sum_{k=1}^K h\silk s_k+n_l,
\end{equation}
where $p$ is the transmit power of a user, $h\silk\sim\mathcal{CN}(0,1)$ is the channel between user $k$ and AP $l$, $s_k\sim\mathcal{CN}(0,1)$ is the transmitted symbol from user $k$, and $n_l\sim\mathcal{CN}(0,\sigma^2)$ is the noise at AP $l$. Hence, the received signal at all APs is given as
\begin{equation}\label{eq:ReceivedSignalAll}
\mbfy=\sqrt{p}\mbfH\mbfs+\mbfn,
\end{equation}
where ${\mbfy=\left[y_1 \ldots y_L\right]^T}$, $\mbfs$ and $\mbfn$ are defined similarly, and the channel matrix between the users and APs is given as
\begin{equation}\label{eq:H}
\mbfH=
\begin{bmatrix}
h_{11} & \ldots & h_{1K}\\
\vdots & \ddots & \vdots\\
h_{L1} & \ldots & h_{LK}\\
\end{bmatrix}.
\end{equation}

At the network controller (NC), the received signals from the users are combined as follows
\begin{equation}\label{eq:Combining}
\mbfV^H\mbfy,
\end{equation}
where ${\mbfV=[\mbfv_1 \ldots \mbfv_K]\in\mathbb{C}^{L\times K}}$ is the combining matrix whose $k\ssth$ column decodes the symbol of user $k$. A possible combining matrix can be given as a sum mean-square error (SMSE) minimizer 
\begin{equation}\label{eq:SMSE}
\underset{\mbfV}{\arg\min}~\varepsilon=E\{\|\mbfV^H\mbfy-\mbfs\|_2^2\}.
\end{equation}
The solution to \eqref{eq:SMSE} is known as the minimum mean-square error (MMSE) receiver where the vector filters for all APs and users contribute to minimize the SMSE although their contributions can be small. Sparsity inducing terms can be included in \eqref{eq:SMSE} to silence APs and users. Hence, the backhaul traffic load can be significantly reduced as well as the total network power consumption and computational complexity.

$\varepsilon$ in \eqref{eq:SMSE} can be further rewritten as
\begin{align}
\varepsilon=&E\{\|\sqrt{p}\mbfV^H\mbfH\mbfs-\mbfs\|_2^2\}+E\{\|\mbfV^H\mbfn\|_2^2\}\nonumber\\
=&p~\!\ttr\{\mbfQ^H\mbfQ\}+\sigma^2\ttr\{\mbfV^H\mbfV\},
\end{align}
where $\mbfQ=\mbfV^H\mbfH-\mbfI$.

Assuming maximum $M$ out of $K$ users are selected at the NC, the combining matrix can be further constrained with the inequality
\begin{equation}\label{eq:l0norm}
\|\mbfV\|_{2,0}\leq M,
\end{equation}
where $\ell_{p,q}$ norm is defined as 
\begin{equation}
\|\mbfV\|_{p,q}=\left[\sum_{k=1}^K(\|\mbfv_k\|_p)^q\right]^{(1/q)}.
\end{equation}
Relaxing the $\ell_0$ norm in \eqref{eq:l0norm} with the $\ell_1$ norm, the joint user selection and combining problem can be given in an unconstrained form as 
\begin{equation}\label{eq:UnconstrainedForm}
\underset{\mbfV}{\arg\min}~p\|\mbfV^H\mbfH-\mbfI\|_F^2+\sigma^2\|\mbfV\|_F^2+\mu\|\mbfV\|_{2,1},
\end{equation}
where $\mu$ is the regularizer.

The third summand in \eqref{eq:UnconstrainedForm} induces sparsity at the group level, i.e., the penalty term enforces some users to be silenced. To induce sparsity within the group level, i.e., the penalty term enforces some APs to be silenced, the conventional lasso penalty can be added to \eqref{eq:UnconstrainedForm} 
\begin{align}\label{eq:SGL}
\underset{\mbfV}{\arg\min}&~p\|\mbfV^H\mbfH-\mbfI\|_F^2+\sigma^2\|\mbfV\|_F^2+\alpha\mu\|\mbfV\|_{2,1}\nonumber\\
&+(1-\alpha)\mu\sum_{l=1}^L\sum_{k=1}^K|v\silk|,
\end{align}
where ${\alpha\in[0,1]}$ is for the convex combination of the lasso and group lasso penalties, i.e., ${\alpha=0}$ and ${\alpha=1}$ give the lasso and group lasso fits, respectively.


\section{Numerical Results} \label{sec:NumericalResults}
In this section, the presented numerical results demonstrate the effectiveness of the proposed sparse group lasso (SGL) solution to reduce the backhaul traffic load at the cost of acceptable loss in $\mbsr$. We assume log-normal shadowing, distance, penetration loss, and power efficiency vary with uniform distribution between $7\text{-}9$ dB, $35\text{-}50$ m, and $20\text{-}30$ dB, and $5\text{-}10\%$, respectively. Finally, we assume the channel center frequency, bandwidth, noise figure, and transmit power are $2$ GHz, $10$ MHz, $5$ dB, and $20$ dBm, respectively. The channel gains are drawn i.i.d. from ${\mathcal{CN}(0,1)}$ distribution. The number of channel realizations is set to $100$. 
%! favorable trade-off! use this in your paper

In Table \ref{tab:Compare}, the numerical results for $K=16$ users and $L=32,64,128$ APs are presented for the SGL solver \eqref{eq:SGL}
and the MMSE combining matrices. For the results in Table \ref{tab:Compare}, the sparsity percentage of the network is  set to $30\%$, i.e., nearly one third of the links in a network is significantly weaker than the other links. For the results, SGL solver parameters in \eqref{eq:SGL} are held fixed.

The $\mbsrs$ of SGL and MMSE are given in the $2$nd and $4$th columns, respectively. Their percentage differences are given in the $5$th column. The sparsity percentage of the SGL solver is given in the $3$rd column. For instance, for the $L=128$ case, $12\%$ indicates that nearly one tenth of the elements in the $\mbfV$ combining matrix is zero. Thus, the backhaul traffic load is dropped by $88\%$. Whereas the $\mbsr$ loss is $43\%$. 

As seen in Table \ref{tab:Compare}, the chosen SGL solver parameters yield the $30\%$ sparsity only for the $L=64$ case. The SGL solver parameters in \eqref{eq:SGL} can be tuned to achieve $30\%$ sparsity for other cases $L=32,128$ as well. As expected, as the degrees of freedom in the network increase, e.g., $L$ is increased, sparser solutions can be obtained for fixed SGL parameters. While sparser solutions can reduce the backhaul traffic load significantly, the $\mbsr$ loss also increases. However, as the network size is doubled, the sparsity is also nearly halved while the $\mbsr$ loss trend is less than halved when $L=64,128$ cases are compared.

The last column in Table \ref{tab:Compare} indicates the decision accuracy of the SGL solver. For instance, the link accuracy would be perfect, i.e., $100\%$, if the zero elements in $\mbfV$ correspond to the weaker links that make up $30\%$ in the channel matrix $\mbfH$. 

Note that the conventional application of sparse solver is to estimate the unknown sparse $\mbfX$. Hence, the known measurement matrix, e.g., $\mbfPhi$ is not necessarily sparse
\begin{equation}
\mbfY_\text{ss} = \mbfPhi \mbfX.
\end{equation}
Here, the ss subindex stands for sparse solver. Whereas, in our work, the known channel matrix $\mbfH$ is sparse and we enforce a sparse $\mbfV$ solution by using the SGL solver  
\begin{equation}
\mbfY_\text{cf} = \mbfV^H \mbfH .
\end{equation}
Here, the cf subindex stands for $\mbcf$ network. Note that $\mbfY_\text{cf}=\mbfI$ as seen in $\eqref{eq:SGL}$ for our $\mbcf$ network problem.

Moreover, in sparse solver applications, some elements of the unknown sparse $\mbfX$ matrix are exactly zero. Whereas in our work, none of the elements of the known $\mbfH$ matrix are zero but as mentioned earlier, some of them have significantly smaller values, i.e., weaker links, than the others. Due to these deviations from conventional sparse solver applications, the link accuracies are moderate as seen in Table \ref{tab:Compare}. However, as mentioned earlier, the SGL application in our work is effective since the traffic load trend is halved while the $\mbsr$ loss trend is less than halved as the network size is doubled. 

Nevertheless, if the ergodic sparsity of a given network is known, e.g., we assume $30\%$ for all cases in Table \ref{tab:Compare}, the SGL parameters can be tuned so that $30\%$ sparse $\mbfV$ solutions are obtained for all cases. As seen in the $L=64$ case, the backhaul traffic load is dropped by $70\%$ while the $\mbsr$ loss is only $30\%$.

Note that further benefits can be gained by selecting APs and users in the network, i.e., by silencing some of them. For instance, if a user (an AP) has stronger links only to $10\%$ of the APs (users) in the network, that user (AP) can be silenced. Therefore, not only the backhaul traffic load, but also the total power consumption in the network can be reduced by silencing some users. In Table \ref{tab:Compare}, the randomly generated channel matrices $\mbfH$ do not have zero columns or rows, i.e., some columns or rows are all zeros. Thus, there is no silenced AP or user in the network, i.e., $\mbfV$ has no zero columns or rows. As mentioned earlier, further benefits, e.g., reduced total power consumption, can be obtained if the channel matrix $\mbfH$ has zero (i.e., weaker links) or nearly zero columns or rows.

Next, we present the bit error rate (BER) results since the problem objective $\eqref{eq:SMSE}$ intends to lower the BER of the network. ...

\begin{table}[!t]
\scriptsize 
\begin{center}
\caption{SUM-RATE AND OTHER RESULTS OF SGL AND MMSE COMBINING MATRICES.} \label{tab:Compare}\vspace{-.2cm}
\begin{tabular}{|c|c|c|c|c|c|}\hline
$L$ & SGL $\mbsr$& Sparsity $\%$ & MMSE $\mbsr$ & Sum-rate Diff. $\%$ & Link Acc. $\%$ \\\hline
$32$ & 96 & 64 & 111 & 14 & 59 \\\hline
$64$ & 99 & 31 & 137 & 29 & 49 \\\hline
$128$ & 89 & 12 & 158 & 43 & 38 \\\hline
\end{tabular}
\end{center}
\vspace{-.5cm}
\end{table}

\bibliographystyle{IEEEtran}

\bibliography{F:/Bibliography/IEEEAbrv,F:/Bibliography/OnlineResources,F:/Bibliography/IEEEfullA_v02}

\end{document}



